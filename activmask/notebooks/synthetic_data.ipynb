{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "from datasets.synth import SyntheticDataset\n",
    "import json\n",
    "import medpy\n",
    "import collections\n",
    "import h5py\n",
    "import ntpath\n",
    "import matplotlib.pyplots plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Dataset\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "goal: randomly generate a dataset of images with the following properties:\n",
    "    training set:\n",
    "        class 0: two cross symbols as the main predictor (add noise and random cropping of \n",
    "                 crosses to make less predictive). single solid rectangle in lower left \n",
    "                 corner as a distractor.\n",
    "        class 1: one cross symbol as main predictor. single solid rectangle in lower \n",
    "                 right corner as distractor\n",
    "    test set:\n",
    "        Same as training but the relationship between the               \n",
    "         \n",
    "\"\"\"\n",
    "\n",
    "def add_cross(img, class_label, cross_dims=5, add_noise=False):\n",
    "    \"\"\" Add the predictive cross(es) to the image arbirarily (may accidentally intersect the distractor, but\n",
    "            that's ok). Class label defines how many times the cross is placed to ensure no overlap\n",
    "    \n",
    "        Args: \n",
    "            class_label: 0 or 1\n",
    "            add_noise: True/False - if True, add blurring, randomly truncate cross limbs proportional to how\n",
    "                        long they are\n",
    "    \"\"\"\n",
    "\n",
    "    x_centres = np.random.choice(range(cross_dims, 28-cross_dims), size=[class_label + 1], replace=False)\n",
    "    y_centres = np.random.choice(range(cross_dims, 28-cross_dims), size=[class_label + 1], replace=False)\n",
    "    for i in range(class_label+1):\n",
    "\n",
    "        centre_x = x_centres[i]\n",
    "        centre_y = y_centres[i]\n",
    "        img[centre_x-cross_dims:centre_x+cross_dims+1, centre_y] = 1\n",
    "        img[centre_x, centre_y-cross_dims:centre_y+cross_dims+1] = 1\n",
    "\n",
    "        \n",
    "def add_distractor(img, class_label, tag_dims=[2,3], add_noise=False):\n",
    "    \"\"\"\n",
    "    Add a distractor for prediction based on the class label - zero puts it on the left, one puts it on the\n",
    "            right\n",
    "        \n",
    "        Args:\n",
    "            tag_dims: list of the sizes for the rectangular distractor tag\n",
    "            add_noise: True/False - if True, blurs the distractor and also shifts its location by some\n",
    "                        random amount fixed within 2-5 pixels from the edges of the image\n",
    "    \"\"\"\n",
    "    tag_buffer = 5\n",
    "    size_x, size_y = img.shape\n",
    "    if class_label == 0:\n",
    "        # buffer of 5 from the border\n",
    "        img[size_y-tag_buffer-tag_dims[0]:size_y-tag_buffer, tag_buffer:tag_buffer+tag_dims[1]] = 1\n",
    "        tag_centre_x = (tag_buffer+tag_dims[1]) // 2\n",
    "        tag_centre_y = 1\n",
    "    else:\n",
    "        img[size_y-tag_buffer-tag_dims[0]:size_y-tag_buffer, size_x-tag_buffer-tag_dims[1]:size_x-tag_buffer] = 1\n",
    "\n",
    "        \n",
    "def make_synthetic_dataset(length, mode, folder, root=\"../data/synth3\", img_size=28, seed=0):\n",
    "    \"\"\" \n",
    "    Dataset Builder\n",
    "    Parameters: \n",
    "        length: how many images should be generated\n",
    "        mode: string of either train or test\n",
    "    \n",
    "    \"\"\"\n",
    "    labels = {}\n",
    "    labels_dict = pd.DataFrame(columns=[\"file\",\"class\"])\n",
    "    np.random.seed(seed)\n",
    "    for n in range(length):\n",
    "        print(\"making \", n, \" of \", length, \" files\")\n",
    "        if n < length//2:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1 # even data split\n",
    "\n",
    "        img_base = np.zeros([img_size,img_size])\n",
    "        add_cross(img_base, label, 5)  # np.random.randint(3,5)\n",
    "        img_seg = np.zeros([img_size,img_size])\n",
    "        img_seg[:,:] = img_base[:,:]\n",
    "        \n",
    "        if mode == 'distractor':\n",
    "            add_distractor(img_base, label)\n",
    "        \n",
    "        # save image and segmentation map to file\n",
    "        np.save(\"{}/{}_img_{}.npy\".format(root, folder, n), img_base)\n",
    "        np.save(\"{}/{}_seg_{}.npy\".format(root, folder, n), img_seg)\n",
    "\n",
    "        labels[\"{}/{}_img_{}.npy\".format(root, folder, n)] = label\n",
    "\n",
    "    labels_dict[\"file\"] = labels.keys()\n",
    "    labels_dict[\"file\"] = labels_dict[\"file\"].str.replace(root,\"\")\n",
    "    labels_dict[\"file\"] = labels_dict[\"file\"].str.replace(\"/\",\"\")\n",
    "    labels_dict[\"class\"] = labels.values()\n",
    "    labels_dict = labels_dict.set_index(\"file\")\n",
    "    labels_dict.to_csv(\"{}/{}_labels.csv\".format(root, folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_synthetic_dataset(512, \"distractor\", \"distractor1\", seed=1)\n",
    "make_synthetic_dataset(512, \"distractor\", \"distractor2\", seed=2)\n",
    "make_synthetic_dataset(512, \"distractor\", \"distractor3\", seed=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View Dataset\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets.\n",
    "DATAROOT = \"../../data/synth2/\"\n",
    "train = SyntheticDataset(dataroot=DATAROOT, mode=\"distractor1\", \n",
    "    blur=3, nsamples=10, distract_noise=0)\n",
    "valid = SyntheticDataset(dataroot=DATAROOT, mode=\"distractor2\", \n",
    "    blur=3, nsamples=10, distract_noise=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7dd711cce678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loop stuff.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m titles = [\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;34m\"D_train, Class 0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"D_train, Class 1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# Loop stuff.\n",
    "dataloaders = [train, valid]\n",
    "images = [[1,5],[4,6]]\n",
    "titles = [\n",
    "    [\"D_train, Class 0\", \"D_train, Class 1\"],\n",
    "    [\"D_valid, Class 0\", \"D_valid, Class 1\"]\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, squeeze=True)\n",
    "\n",
    "for i, ax_dist in enumerate(axs):\n",
    "    for j, ax in enumerate(ax_dist):\n",
    "        img = dataloaders[i][images[i][j]]\n",
    "        \n",
    "        ax.imshow(img[0][0][0], interpolation='none', cmap='Greys_r')\n",
    "        ax.set_title(titles[i][j])\n",
    "        ax.get_xaxis().set_visible(False)       \n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "fig.set_tight_layout(tight=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
